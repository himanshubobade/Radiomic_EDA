{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66148a85-04e5-4fe3-b5c9-7a8b2dba2f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "349c3252-96d8-4bcc-8825-bbaca2daf070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "kpca__kernel           sigmoid\n",
      "kpca__n_components          30\n",
      "tsne__perplexity             7\n",
      "kmeans__n_clusters           5\n",
      "score_a               0.725367\n",
      "score_b               0.838268\n",
      "Name: 8, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load your data\n",
    "file_path = \"data/radiomic78_2824.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Use SimpleImputer to fill in missing values with the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = imputer.fit_transform(df)\n",
    "\n",
    "# Convert the imputed array back to a DataFrame\n",
    "df_imputed = pd.DataFrame(df_imputed, columns=df.columns)\n",
    "\n",
    "# Continue with the rest of your code\n",
    "csv_file_path = \"data/data.csv\"\n",
    "df_imputed.to_csv(csv_file_path, encoding='utf-8', index=False)\n",
    "\n",
    "# Extract the 'patient_id' column (assuming it's not part of the data for scaling)\n",
    "patient_id = df_imputed['patient_id']\n",
    "\n",
    "# Drop the 'patient_id' column for scaling\n",
    "df_imputed = df_imputed.drop(columns=['patient_id'])\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "scaled_data = scaler.fit_transform(df_imputed)\n",
    "\n",
    "# Create a new DataFrame with the scaled data\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=df_imputed.columns)\n",
    "\n",
    "# Function to perform clustering stability test with bootstrapping\n",
    "def cluster_stability_train_test(X_train, X_test, est, n_iter=50, random_state=None):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    labels_test = []\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        # Draw bootstrap samples\n",
    "        sample_indices = resample(np.arange(X_train.shape[0]), random_state=rng)\n",
    "\n",
    "        # Clone the estimator to ensure a fresh model for each iteration\n",
    "        est_copy = clone(est)\n",
    "        \n",
    "        if hasattr(est_copy, \"random_state\"):\n",
    "            # Randomize the estimator if possible\n",
    "            est_copy.random_state = rng.randint(1e5)\n",
    "        \n",
    "        X_bootstrap = X_train[sample_indices]\n",
    "        est_copy.fit(X_bootstrap)\n",
    "        \n",
    "        # Predict on the test data\n",
    "        relabel_test = est_copy.predict(X_test)\n",
    "        labels_test.append(relabel_test)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    # Calculate adjusted Rand scores between pairs of labelings\n",
    "    for i in range(len(labels_test) - 1):\n",
    "        labels_1 = labels_test[i]\n",
    "        labels_2 = labels_test[i + 1]\n",
    "        scores.append(adjusted_rand_score(labels_1, labels_2))\n",
    "\n",
    "    # Return the mean adjusted Rand score\n",
    "    return np.mean(scores)\n",
    "\n",
    "def hypersearch(X_std, kpca_params=None, tsne_params=None, kmeans_params=None, n_jobs=-1):\n",
    "    # 90% split\n",
    "    X_train, X_test = train_test_split(X_std, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Define default hyperparameter values\n",
    "    default_kpca_params = {\n",
    "        'kernel': ['sigmoid'],\n",
    "        'n_components': [10]\n",
    "    }\n",
    "    default_tsne_params = {\n",
    "        'perplexity': [10]\n",
    "    }\n",
    "    default_kmeans_params = {\n",
    "        'n_clusters': [5]\n",
    "    }\n",
    "\n",
    "    # Handle None values for hyperparameters and set default values\n",
    "    kpca_params = kpca_params or default_kpca_params\n",
    "    kpca_params['kernel'] = kpca_params.get('kernel', default_kpca_params['kernel'])\n",
    "    kpca_params['n_components'] = kpca_params.get('n_components', default_kpca_params['n_components'])\n",
    "    \n",
    "    tsne_params = tsne_params or default_tsne_params\n",
    "    tsne_params['perplexity'] = tsne_params.get('perplexity', default_tsne_params['perplexity'])\n",
    "\n",
    "    kmeans_params = kmeans_params or default_kmeans_params\n",
    "    kmeans_params['n_clusters'] = kmeans_params.get('n_clusters', default_kmeans_params['n_clusters'])\n",
    "\n",
    "    # Create a pipeline with named steps\n",
    "    pipeline = Pipeline([\n",
    "        ('kpca', KernelPCA()),\n",
    "        ('tsne', TSNE()),\n",
    "    ])\n",
    "\n",
    "    param_grid = {}\n",
    "    for param, values in kpca_params.items():\n",
    "        param_grid['kpca__' + param] = values\n",
    "    for param, values in tsne_params.items():\n",
    "        param_grid['tsne__' + param] = values\n",
    "\n",
    "\n",
    "    # Get KMeans n_clusters values\n",
    "    kmeans_n_clusters = kmeans_params.get('n_clusters', [5])\n",
    "\n",
    "    # Generate all possible parameter combinations\n",
    "    param_combinations = list(ParameterGrid(param_grid))\n",
    "\n",
    "    # Create an empty DataFrame to store scores\n",
    "    columns = list(param_grid.keys()) + ['kmeans__n_clusters', 'score_a', 'score_b']\n",
    "    scores_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Iterate over parameter combinations in parallel\n",
    "    def evaluate_params(params):\n",
    "        scores_data = []\n",
    "        for n_clusters in kmeans_n_clusters:\n",
    "            pipeline_cloned = clone(pipeline)\n",
    "            pipeline_cloned.set_params(**params)\n",
    "\n",
    "            X_transformed = pipeline_cloned.fit_transform(X_train)\n",
    "            X_test_transformed = pipeline_cloned.named_steps['kpca'].transform(X_test)\n",
    "            X_test_transformed = pipeline_cloned.named_steps['tsne'].fit_transform(X_test_transformed)\n",
    "            print(X_test_transformed.shape)\n",
    "\n",
    "            score_a = cluster_stability_train_test(X_transformed, X_test_transformed, KMeans(n_clusters=n_clusters, n_init=10), n_iter=50, random_state=42)\n",
    "\n",
    "            X_combined = np.vstack((X_transformed, X_test_transformed))\n",
    "            X_test_tsne_combined = pipeline_cloned.named_steps['tsne'].fit_transform(X_combined)[-X_test.shape[0]:]\n",
    "            score_b = cluster_stability_train_test(X_transformed, X_test_tsne_combined, KMeans(n_clusters=n_clusters, n_init=10), n_iter=50, random_state=42)\n",
    "\n",
    "            row = {**params, 'kmeans__n_clusters': n_clusters, 'score_a': score_a, 'score_b': score_b}\n",
    "            scores_data.append(row)\n",
    "        return scores_data\n",
    "\n",
    "    # Parallelize the parameter grid search\n",
    "    scores_data = Parallel(n_jobs=n_jobs)(delayed(evaluate_params)(params) for params in param_combinations)\n",
    "\n",
    "    # Create the DataFrame from the collected scores\n",
    "    scores_df = pd.DataFrame([item for sublist in scores_data for item in sublist])\n",
    "\n",
    "    # Find the best hyperparameter combination\n",
    "    best_hyperparameter = scores_df.loc[scores_df[['score_a', 'score_b']].mean(axis=1).idxmax()]\n",
    "\n",
    "    return scores_df, best_hyperparameter\n",
    "\n",
    "# Specify the parameter search space\n",
    "kpca_params = {\n",
    "    'kernel': ['sigmoid'],\n",
    "    'n_components': [10, 20, 30, 40]  # Add more values if needed\n",
    "}\n",
    "\n",
    "tsne_params = {\n",
    "    'perplexity': [7]  # Add more values if needed\n",
    "}\n",
    "\n",
    "kmeans_params = {\n",
    "    'n_clusters': [3, 4, 5]  # Add more values if needed\n",
    "}\n",
    "\n",
    "# Call the hypersearch function\n",
    "scores, best_hyperparameter = hypersearch(scaled_df, kpca_params, tsne_params, kmeans_params)\n",
    "\n",
    "# Print the results\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_hyperparameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a35077b-98cb-46c3-86c6-1ffcfcaf67da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kpca__kernel</th>\n",
       "      <th>kpca__n_components</th>\n",
       "      <th>tsne__perplexity</th>\n",
       "      <th>kmeans__n_clusters</th>\n",
       "      <th>score_a</th>\n",
       "      <th>score_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.534009</td>\n",
       "      <td>0.589794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.686222</td>\n",
       "      <td>0.646562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.495314</td>\n",
       "      <td>0.516548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.643124</td>\n",
       "      <td>0.511123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.629077</td>\n",
       "      <td>0.588673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.396049</td>\n",
       "      <td>0.688667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.456145</td>\n",
       "      <td>0.816212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.448507</td>\n",
       "      <td>0.839868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.725367</td>\n",
       "      <td>0.838268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.259454</td>\n",
       "      <td>0.358840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.280197</td>\n",
       "      <td>0.532244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.633505</td>\n",
       "      <td>0.789720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kpca__kernel  kpca__n_components  tsne__perplexity  kmeans__n_clusters  \\\n",
       "0       sigmoid                  10                 7                   3   \n",
       "1       sigmoid                  10                 7                   4   \n",
       "2       sigmoid                  10                 7                   5   \n",
       "3       sigmoid                  20                 7                   3   \n",
       "4       sigmoid                  20                 7                   4   \n",
       "5       sigmoid                  20                 7                   5   \n",
       "6       sigmoid                  30                 7                   3   \n",
       "7       sigmoid                  30                 7                   4   \n",
       "8       sigmoid                  30                 7                   5   \n",
       "9       sigmoid                  40                 7                   3   \n",
       "10      sigmoid                  40                 7                   4   \n",
       "11      sigmoid                  40                 7                   5   \n",
       "\n",
       "     score_a   score_b  \n",
       "0   0.534009  0.589794  \n",
       "1   0.686222  0.646562  \n",
       "2   0.495314  0.516548  \n",
       "3   0.643124  0.511123  \n",
       "4   0.629077  0.588673  \n",
       "5   0.396049  0.688667  \n",
       "6   0.456145  0.816212  \n",
       "7   0.448507  0.839868  \n",
       "8   0.725367  0.838268  \n",
       "9   0.259454  0.358840  \n",
       "10  0.280197  0.532244  \n",
       "11  0.633505  0.789720  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb185b5b-5971-4644-90ba-0b7fc05c41d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c804273-b07f-418a-b082-9902240efb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df85d1bb-46db-4caa-b675-145192fb0fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173204f2-29af-49b4-91d5-9059b4721547",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dimred",
   "language": "python",
   "name": "dimred"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
